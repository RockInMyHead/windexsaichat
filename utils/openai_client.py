import os
import tempfile
from typing import Any, Dict, List

from dotenv import load_dotenv
from openai import OpenAI
import httpx

load_dotenv()

# OpenAI API Configuration
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY") or os.getenv("WINDEXAI_API_KEY")

# Proxy Configuration
PROXY_ENABLED = os.getenv("PROXY_ENABLED", "false").lower() == "true"
PROXY_HOST = os.getenv("PROXY_HOST")
PROXY_PORT = os.getenv("PROXY_PORT")
PROXY_USERNAME = os.getenv("PROXY_USERNAME")
PROXY_PASSWORD = os.getenv("PROXY_PASSWORD")

# Build proxy URL if enabled
proxy_url = None
if PROXY_ENABLED and PROXY_HOST and PROXY_PORT:
    if PROXY_USERNAME and PROXY_PASSWORD:
        proxy_url = f"http://{PROXY_USERNAME}:{PROXY_PASSWORD}@{PROXY_HOST}:{PROXY_PORT}"
    else:
        proxy_url = f"http://{PROXY_HOST}:{PROXY_PORT}"
    print(f"üåê Proxy enabled: {PROXY_HOST}:{PROXY_PORT}")

# Initialize OpenAI client always using a simple httpx Client
if OPENAI_API_KEY and OPENAI_API_KEY != "sk-demo-key-replace-with-real-openai-key":
    try:
        if proxy_url:
            http_client = httpx.Client(
                proxies={
                    "http://": proxy_url,
                    "https://": proxy_url,
                }, 
                timeout=120.0
            )
            print(f"‚úÖ OpenAI client initialized successfully with proxy {proxy_url}")
        else:
            http_client = httpx.Client(timeout=120.0)
            print("‚úÖ OpenAI client initialized successfully")
        openai_client = OpenAI(api_key=OPENAI_API_KEY, http_client=http_client)
    except Exception as e:
        print(f"‚ùå Warning: Failed to initialize OpenAI client: {e}")
        openai_client = None
else:
    print("‚ö†Ô∏è OpenAI API key not configured")
    openai_client = None

# Import new AI configuration
try:
    from .ai_config import (get_enhanced_user_prompt, get_generation_params,
                            get_model_config, get_system_prompt)
except ImportError as e:
    print(f"Warning: Could not import ai_config: {e}")
    # Fallback functions
    def get_enhanced_user_prompt(message): return message
    def get_generation_params(model): return {}
    def get_model_config(model): return {}
    def get_system_prompt(): return ""

# Legacy MODELS dict for backward compatibility
MODELS = {
    "gpt-4o-mini": {
        "name": "WIndexAI Lite",
        "description": "–ë—ã—Å—Ç—Ä–∞—è –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –ø–æ–≤—Å–µ–¥–Ω–µ–≤–Ω—ã—Ö –∑–∞–¥–∞—á",
        "max_tokens": 2000,
        "temperature": 0.7,
        "top_p": 0.9,
    },
    "gpt-4o": {
        "name": "WIndexAI Pro",
        "description": "–ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –º–æ–¥–µ–ª—å —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º–∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—è–º–∏",
        "max_tokens": 6000,
        "temperature": 0.65,
        "top_p": 0.95,
    },
}


def get_openai_client() -> OpenAI:
    """Get OpenAI client instance"""
    return openai_client


def get_model_config(model_name: str) -> Dict[str, Any]:
    """Get model configuration - now uses new AI config"""
    from .ai_config import get_model_config as get_ai_model_config

    return get_ai_model_config(model_name)


def generate_response(
    messages: List[Dict[str, str]], model: str = "gpt-4o-mini"
) -> str:
    """Generate AI response using OpenAI API with enhanced analytical system"""
    if not openai_client:
        return "‚ö†Ô∏è OpenAI API –∫–ª—é—á –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –¥–æ–±–∞–≤—å—Ç–µ –≤–∞—à API –∫–ª—é—á –≤ —Ñ–∞–π–ª .env"

    try:
        # Get generation parameters from new config
        gen_params = get_generation_params(model)

        # Prepare enhanced messages
        enhanced_messages = []

        # Add system prompt
        system_prompt = get_system_prompt()
        enhanced_messages.append(system_prompt)

        # Process user messages and enhance the last user message
        for i, msg in enumerate(messages):
            if msg.get("role") == "user" and i == len(messages) - 1:
                # This is the last user message - enhance it
                enhanced_user_prompt = get_enhanced_user_prompt(msg["content"])
                enhanced_messages.append(
                    {"role": "user", "content": enhanced_user_prompt}
                )
            else:
                # Keep other messages as is
                enhanced_messages.append(msg)

        response = openai_client.chat.completions.create(
            model=gen_params["model"],
            messages=enhanced_messages,
            max_tokens=gen_params["max_tokens"],
            temperature=gen_params["temperature"],
            top_p=gen_params["top_p"],
            stream=False,
        )

        return response.choices[0].message.content

    except Exception as e:
        # –ë–æ–ª–µ–µ –¥–µ—Ç–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫
        if "max_tokens" in str(e):
            return (
                "–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ –º–æ–¥–µ–ª–∏. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑."
            )
        elif "rate_limit" in str(e).lower():
            return "–ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–¥–æ–∂–¥–∏—Ç–µ –Ω–µ–º–Ω–æ–≥–æ –∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞."
        elif "invalid_api_key" in str(e).lower():
            return "–û—à–∏–±–∫–∞ API –∫–ª—é—á–∞. –û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É."
        else:
            return f"–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {str(e)[:100]}..."


def format_messages_for_openai(messages: List[Dict[str, str]]) -> List[Dict[str, str]]:
    """Format messages for OpenAI API"""
    formatted_messages = []

    for message in messages:
        formatted_messages.append(
            {"role": message["role"], "content": message["content"]}
        )

    return formatted_messages


def transcribe_audio(audio_file_path: str) -> str:
    """Transcribe audio file using OpenAI Whisper"""
    if not openai_client:
        print("‚ùå OpenAI client not available for transcription")
        return None

    try:
        print(f"üé§ Transcribing audio file: {audio_file_path}")
        with open(audio_file_path, "rb") as audio_file:
            transcript = openai_client.audio.transcriptions.create(
                model="whisper-1", file=audio_file, language="ru"  # Russian language
            )
        print(f"‚úÖ Transcription successful: {transcript.text[:100]}...")
        return transcript.text
    except Exception as e:
        print(f"‚ùå Transcription error: {e}")
        return None


def text_to_speech(text: str, voice: str = "alloy") -> str:
    """Convert text to speech using OpenAI TTS"""
    if not openai_client:
        print("‚ùå OpenAI client not available for text-to-speech")
        return None

    try:
        print(f"üîä Generating speech for text: {text[:50]}...")
        response = openai_client.audio.speech.create(
            model="tts-1", voice=voice, input=text
        )

        # Save to temporary file
        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".mp3")
        temp_file.write(response.content)
        temp_file.close()

        print(f"‚úÖ Speech generated successfully: {temp_file.name}")
        return temp_file.name
    except Exception as e:
        print(f"‚ùå Text-to-speech error: {e}")
        return None
